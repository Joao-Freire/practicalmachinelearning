---
title: "Practical Machine Learning - Course Project"
author: "Jo√£o Freire"
date: "February 10^th^, 2019"
output: 
  html_document: 
    keep_md: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# 1 - Executive Summary

This report presents **three supervised machine learning models** - *Decision Tree, Gradient Boosting and Random Forest* - built on data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants. They were asked to perform barbell lifts correctly and incorrectly in 5 different ways. More information is available from the website here: http://groupware.les.inf.puc-rio.br/har (see the section on the Weight Lifting Exercise Dataset).

The models predict in which of the 5 different ways a barbell lift was performed, which correspond to the 5 levels of the response variable "classe" in the training data set. The training data set has labeled data and the testing data set for the Prediction Quiz has unlabeled data. The model built with the **Random Forest** algorithm has the **highest accuracy** on the validation data set and was therefore selected for predicting the classes in the testing data set.

# 2 - Data processing

## 2.1 - Data importing

```{r}
pml_train <- read.csv("pml-training.csv")
pml_test <- read.csv("pml-testing.csv")
dim(pml_train)
dim(pml_test)
```

## 2.2 - Data cleaning

### 2.2.1 - Remove variables with NAs

```{r}
# Count the number of NAs per variable in the testing data
sum_na <- colSums(is.na(pml_test))
length(sum_na)
sum_na[1:15]
# Identify the indexes of variables without NAs in the testing data
indexes_col_not_na <- which(sum_na==0)
length(indexes_col_not_na)
indexes_col_not_na[1:15]
# The training data will now consist of the same variables
pml_train <- pml_train[,indexes_col_not_na]
dim(pml_train)
# Check if there are NAs
unique(colSums(is.na(pml_train)))
# Only the response variable in the training data has a different name
colnames(pml_train)[60]
colnames(pml_test[,indexes_col_not_na])[60]
identical(colnames(pml_train)[1:59],colnames(pml_test[,indexes_col_not_na])[1:59])
```

### 2.2.2 - Remove variables with irrelevant information for training the models

```{r}
str(pml_train)
# The first 7 variables will be removed
pml_train <- pml_train[,-c(1:7)]
dim(pml_train)
```

## 2.3 - Create training (80%) and validation (20%) data sets

```{r}
library(caret)
set.seed(12300)
in_train <- createDataPartition(y=pml_train$classe,p=0.8,list=FALSE)
pml_training <- pml_train[in_train,]
pml_validation <- pml_train[-in_train,]
dim(pml_training)
dim(pml_validation)
nrow(pml_training)+nrow(pml_validation)==nrow(pml_train)
```

# 3 - Supervised Machine Learning Algorithms

## 3.1 - Decision Tree

```{r}
train_ctrl <- trainControl(method="repeatedcv",
                           number=10, # 10-fold cross validation 
                           repeats=3 # Repeated 3 times
                           )

mod_dt <- train(classe~.,method="rpart",data=pml_training,
                trControl=train_ctrl)

library(rattle)
fancyRpartPlot(mod_dt$finalModel,caption="Decision Tree")
mod_dt_predictions <- predict(mod_dt,newdata=pml_validation)
mod_dt_cm <- confusionMatrix(mod_dt_predictions,pml_validation$classe)
mod_dt_cm
```

## 3.2 - Gradient Boosting

```{r}
mod_gbm <- train(classe~.,method="gbm",data=pml_training,
                 trControl=trainControl(method="cv",
                                        number=5 # 5-fold cross validation
                                        ),verbose=FALSE)
mod_gbm
plot(mod_gbm)
mod_gbm_predictions <- predict(mod_gbm,newdata=pml_validation)
mod_gbm_cm <- confusionMatrix(mod_gbm_predictions,pml_validation$classe)
mod_gbm_cm
```

## 3.3 - Random Forest

```{r}
mod_rf <- train(classe~.,method="rf",data=pml_training,
                 trControl=trainControl(method="cv",
                                        number=5 # 5-fold cross validation
                                        ))
mod_rf
plot(mod_rf$finalModel,main="Random Forest")
mod_rf_predictions <- predict(mod_rf,newdata=pml_validation)
mod_rf_cm <- confusionMatrix(mod_rf_predictions,pml_validation$classe)
mod_rf_cm
```

# 4 - Model selection

```{r}
mod_accuracy <- rbind("Decision Tree"=mod_dt_cm$overall[1],
                      "Gradient Boosting"=mod_gbm_cm$overall[1],
                      "Random Forest"=mod_rf_cm$overall[1])
mod_accuracy
```

**The model with the highest accuracy on the validation data is the mod_rf model, built with the Random Forest algorithm, and will be selected for predicting the classes in the testing data set.**

## 4.1 - Expected out of sample error

```{r}
1-mod_rf_cm$overall[1]
paste("The expected out of sample error is",round((1-mod_rf_cm$overall[1])*100,3),"%")
```

# 5 - Predictions on the testing data

```{r}
test_predictions <- predict(mod_rf,newdata=pml_test)
test_predictions
```
